{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# **Autoencoder Model for Word Embedding**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## I. Import necessary things"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # lower case text\n",
    "    text = text.lower()\n",
    "    # remove punctuations\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(corpus):\n",
    "  corpus_clean = text_cleaner(corpus)\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  word_tokens = word_tokenize(corpus_clean)\n",
    "  \n",
    "  return [w for w in word_tokens if not w in stop_words]"
   ]
  },
  {
   "source": [
    "## II. Load corpus and preprocess it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Donald J. Trump is the 45th President of the United States. He believes the United States has incredible potential and will go on to exceed even its remarkable achievements of the past.\n",
    "Donald J. Trump defines the American success story. Throughout his life he has continually set the standards of business and entrepreneurial excellence, especially in real estate, sports, and entertainment. Mr. Trump built on his success in private life when he entered into politics and public service. He remarkably won the Presidency in his first ever run for any political office.\n",
    "A graduate of the University of Pennsylvania’s Wharton School of Finance, Mr. Trump followed in his father’s footsteps into the world of real estate development, making his mark in New York City. There, the Trump name soon became synonymous with the most prestigious of addresses in Manhattan and, subsequently, throughout the world.\n",
    "Mr. Trump is also an accomplished author. He has written more than fourteen bestsellers.  His first book, The Art of the Deal, is considered a business classic.\n",
    "Mr. Trump announced his candidacy for the Presidency on June 16, 2015. He then accepted the Republican nomination for President of the United States in July of 2016, having defeated 17 other contenders during the Republican primaries.\n",
    "On November 8, 2016, Mr. Trump was elected President in the largest Electoral College landslide for a Republican in 28 years. Mr. Trump won more than 2,600 counties nationwide, the most since President Ronald Reagan in 1984. He received the votes of more than 62 million Americans, the most ever for a Republican candidate.\n",
    "President Trump has delivered historic results in his first term in office despite partisan gridlock in the Nation’s Capital, and resistance from special interests and the Washington Establishment.\n",
    "He passed record-setting tax cuts and regulation cuts, achieved energy independence, replaced NAFTA with the United-States-Mexico-Canada Agreement, invested $2 trillion to completely rebuild the Military, launched the Space Force, obliterated the ISIS Caliphate, achieved a major breakthrough for peace in the Middle East, passed the most significant Veterans Affairs reforms in half a century, confirmed over 250 federal judges, including 2 Supreme Court Justices, signed bipartisan Criminal Justice Reform, lowered drug prices, protected Medicare and Social Security, and secured our nation’s borders.\n",
    "To vanquish the COVID-19 global pandemic, President Trump launched the greatest national mobilization since World War II. The Trump Administration enacted the largest package of financial relief in American history, created the most advanced testing system in the world, developed effective medical treatments to save millions of lives, and launched Operation Warp Speed to deliver a vaccine in record time and defeat the Virus.\n",
    "President Trump has been married to his wife, Melania, for 15 years, and they are parents to their son, Barron. Mr. Trump also has four adult children, Don Jr., Ivanka, Eric, and Tiffany, as well as 10 grandchildren.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Donald J. Trump is the 45th President of the United States. He believes the United States has incredible potential and will go on to exceed even its remarkable achievements of the past.\\nDonald J. Trump defines the American success story. Throughout his life he has continually set the standards of business and entrepreneurial excellence, especially in real estate, sports, and entertainment. Mr. Trump built on his success in private life when he entered into politics and public service. He remarkably won the Presidency in his first ever run for any political office.\\nA graduate of the University of Pennsylvania’s Wharton School of Finance, Mr. Trump followed in his father’s footsteps into the world of real estate development, making his mark in New York City. There, the Trump name soon became synonymous with the most prestigious of addresses in Manhattan and, subsequently, throughout the world.\\nMr. Trump is also an accomplished author. He has written more than fourteen bestsellers.  His first book, The Art of the Deal, is considered a business classic.\\nMr. Trump announced his candidacy for the Presidency on June 16, 2015. He then accepted the Republican nomination for President of the United States in July of 2016, having defeated 17 other contenders during the Republican primaries.\\nOn November 8, 2016, Mr. Trump was elected President in the largest Electoral College landslide for a Republican in 28 years. Mr. Trump won more than 2,600 counties nationwide, the most since President Ronald Reagan in 1984. He received the votes of more than 62 million Americans, the most ever for a Republican candidate.\\nPresident Trump has delivered historic results in his first term in office despite partisan gridlock in the Nation’s Capital, and resistance from special interests and the Washington Establishment.\\nHe passed record-setting tax cuts and regulation cuts, achieved energy independence, replaced NAFTA with the United-States-Mexico-Canada Agreement, invested $2 trillion to completely rebuild the Military, launched the Space Force, obliterated the ISIS Caliphate, achieved a major breakthrough for peace in the Middle East, passed the most significant Veterans Affairs reforms in half a century, confirmed over 250 federal judges, including 2 Supreme Court Justices, signed bipartisan Criminal Justice Reform, lowered drug prices, protected Medicare and Social Security, and secured our nation’s borders.\\nTo vanquish the COVID-19 global pandemic, President Trump launched the greatest national mobilization since World War II. The Trump Administration enacted the largest package of financial relief in American history, created the most advanced testing system in the world, developed effective medical treatments to save millions of lives, and launched Operation Warp Speed to deliver a vaccine in record time and defeat the Virus.\\nPresident Trump has been married to his wife, Melania, for 15 years, and they are parents to their son, Barron. Mr. Trump also has four adult children, Don Jr., Ivanka, Eric, and Tiffany, as well as 10 grandchildren.'"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['donald', 'j', 'trump', 'th', 'president', 'united', 'states', 'believes', 'united', 'states', 'incredible', 'potential', 'go', 'exceed', 'even', 'remarkable', 'achievements', 'past', 'donald', 'j', 'trump', 'defines', 'american', 'success', 'story', 'throughout', 'life', 'continually', 'set', 'standards', 'business', 'entrepreneurial', 'excellence', 'especially', 'real', 'estate', 'sports', 'entertainment', 'mr', 'trump', 'built', 'success', 'private', 'life', 'entered', 'politics', 'public', 'service', 'remarkably', 'presidency', 'first', 'ever', 'run', 'political', 'office', 'graduate', 'university', 'pennsylvania', 'wharton', 'school', 'finance', 'mr', 'trump', 'followed', 'father', 'footsteps', 'world', 'real', 'estate', 'development', 'making', 'mark', 'new', 'york', 'city', 'trump', 'name', 'soon', 'became', 'synonymous', 'prestigious', 'addresses', 'manhattan', 'subsequently', 'throughout', 'world', 'mr', 'trump', 'also', 'accomplished', 'author', 'written', 'fourteen', 'bestsellers', 'first', 'book', 'art', 'deal', 'considered', 'business', 'classic', 'mr', 'trump', 'announced', 'candidacy', 'presidency', 'june', 'accepted', 'republican', 'nomination', 'president', 'united', 'states', 'july', 'defeated', 'contenders', 'republican', 'primaries', 'november', 'mr', 'trump', 'elected', 'president', 'largest', 'electoral', 'college', 'landslide', 'republican', 'years', 'mr', 'trump', 'counties', 'nationwide', 'since', 'president', 'ronald', 'reagan', 'received', 'votes', 'million', 'americans', 'ever', 'republican', 'candidate', 'president', 'trump', 'delivered', 'historic', 'results', 'first', 'term', 'office', 'despite', 'partisan', 'gridlock', 'nation', 'capital', 'resistance', 'special', 'interests', 'washington', 'establishment', 'passed', 'record', 'setting', 'tax', 'cuts', 'regulation', 'cuts', 'achieved', 'energy', 'independence', 'replaced', 'nafta', 'united', 'states', 'mexico', 'canada', 'agreement', 'invested', 'trillion', 'completely', 'rebuild', 'military', 'launched', 'space', 'force', 'obliterated', 'isis', 'caliphate', 'achieved', 'major', 'breakthrough', 'peace', 'middle', 'east', 'passed', 'significant', 'veterans', 'affairs', 'reforms', 'half', 'century', 'confirmed', 'federal', 'judges', 'including', 'supreme', 'court', 'justices', 'signed', 'bipartisan', 'criminal', 'justice', 'reform', 'lowered', 'drug', 'prices', 'protected', 'medicare', 'social', 'security', 'secured', 'nation', 'borders', 'vanquish', 'covid', 'global', 'pandemic', 'president', 'trump', 'launched', 'greatest', 'national', 'mobilization', 'since', 'world', 'war', 'ii', 'trump', 'administration', 'enacted', 'largest', 'package', 'financial', 'relief', 'american', 'history', 'created', 'advanced', 'testing', 'system', 'world', 'developed', 'effective', 'medical', 'treatments', 'save', 'millions', 'lives', 'launched', 'operation', 'warp', 'speed', 'deliver', 'vaccine', 'record', 'time', 'defeat', 'virus', 'president', 'trump', 'married', 'wife', 'melania', 'years', 'parents', 'son', 'barron', 'mr', 'trump', 'also', 'four', 'adult', 'children', 'jr', 'ivanka', 'eric', 'tiffany', 'well', 'grandchildren']\n"
     ]
    }
   ],
   "source": [
    "corpus_token =  preprocess_text(corpus)\n",
    "print(corpus_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary is a list of all tokenized words in corpus_token sorted by alphabet\n",
    "# it can be think of list of unique vocabularies in all documents\n",
    "dictionary = sorted(list(set(corpus_token)))\n",
    "# print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict((c, i) for i, c in enumerate(dictionary))\n",
    "# mapping"
   ]
  },
  {
   "source": [
    "## III. Convert corpus to one-hot vectors & Define embedding dim"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "229\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 20\n",
    "vocab_size = len(dictionary)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "corpus_encode = [mapping[x] for x in corpus_token]\n",
    "onehot_corpus = keras.utils.to_categorical(corpus_encode, num_classes=vocab_size)\n",
    "print(onehot_corpus)"
   ]
  },
  {
   "source": [
    "## IV. Define Autoencoder model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 20)                4600      \n_________________________________________________________________\ndense_7 (Dense)              (None, 229)               4809      \n=================================================================\nTotal params: 9,409\nTrainable params: 9,409\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae_model = keras.Sequential()\n",
    "# ae_model.add(keras.Input(shape=(vocab_size,)))\n",
    "ae_model.add(keras.layers.Dense(embedding_dim, input_dim=vocab_size, activation='relu'))\n",
    "ae_model.add(keras.layers.Dense(vocab_size, input_dim=embedding_dim, activation='softmax'))\n",
    "\n",
    "ae_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "ae_model.summary()"
   ]
  },
  {
   "source": [
    "## V. Train AE model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/1000\n",
      "10/10 [==============================] - 0s 949us/step - loss: 0.0015\n",
      "Epoch 773/1000\n",
      "10/10 [==============================] - 0s 885us/step - loss: 0.0015\n",
      "Epoch 774/1000\n",
      "10/10 [==============================] - 0s 781us/step - loss: 0.0015\n",
      "Epoch 775/1000\n",
      "10/10 [==============================] - 0s 892us/step - loss: 0.0015\n",
      "Epoch 776/1000\n",
      "10/10 [==============================] - 0s 979us/step - loss: 0.0015\n",
      "Epoch 777/1000\n",
      "10/10 [==============================] - 0s 796us/step - loss: 0.0015\n",
      "Epoch 778/1000\n",
      "10/10 [==============================] - 0s 940us/step - loss: 0.0015\n",
      "Epoch 779/1000\n",
      "10/10 [==============================] - 0s 916us/step - loss: 0.0015\n",
      "Epoch 780/1000\n",
      "10/10 [==============================] - 0s 854us/step - loss: 0.0014\n",
      "Epoch 781/1000\n",
      "10/10 [==============================] - 0s 756us/step - loss: 0.0014\n",
      "Epoch 782/1000\n",
      "10/10 [==============================] - 0s 965us/step - loss: 0.0014\n",
      "Epoch 783/1000\n",
      "10/10 [==============================] - 0s 828us/step - loss: 0.0014\n",
      "Epoch 784/1000\n",
      "10/10 [==============================] - 0s 839us/step - loss: 0.0014\n",
      "Epoch 785/1000\n",
      "10/10 [==============================] - 0s 922us/step - loss: 0.0014\n",
      "Epoch 786/1000\n",
      "10/10 [==============================] - 0s 949us/step - loss: 0.0014\n",
      "Epoch 787/1000\n",
      "10/10 [==============================] - 0s 863us/step - loss: 0.0014\n",
      "Epoch 788/1000\n",
      "10/10 [==============================] - 0s 778us/step - loss: 0.0014\n",
      "Epoch 789/1000\n",
      "10/10 [==============================] - 0s 937us/step - loss: 0.0014\n",
      "Epoch 790/1000\n",
      "10/10 [==============================] - 0s 831us/step - loss: 0.0014\n",
      "Epoch 791/1000\n",
      "10/10 [==============================] - 0s 848us/step - loss: 0.0014\n",
      "Epoch 792/1000\n",
      "10/10 [==============================] - 0s 996us/step - loss: 0.0014\n",
      "Epoch 793/1000\n",
      "10/10 [==============================] - 0s 863us/step - loss: 0.0013\n",
      "Epoch 794/1000\n",
      "10/10 [==============================] - 0s 864us/step - loss: 0.0013\n",
      "Epoch 795/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 796/1000\n",
      "10/10 [==============================] - 0s 955us/step - loss: 0.0013\n",
      "Epoch 797/1000\n",
      "10/10 [==============================] - 0s 891us/step - loss: 0.0013\n",
      "Epoch 798/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 799/1000\n",
      "10/10 [==============================] - 0s 831us/step - loss: 0.0013\n",
      "Epoch 800/1000\n",
      "10/10 [==============================] - 0s 792us/step - loss: 0.0013\n",
      "Epoch 801/1000\n",
      "10/10 [==============================] - 0s 981us/step - loss: 0.0013\n",
      "Epoch 802/1000\n",
      "10/10 [==============================] - 0s 878us/step - loss: 0.0013\n",
      "Epoch 803/1000\n",
      "10/10 [==============================] - 0s 800us/step - loss: 0.0013\n",
      "Epoch 804/1000\n",
      "10/10 [==============================] - 0s 797us/step - loss: 0.0013\n",
      "Epoch 805/1000\n",
      "10/10 [==============================] - 0s 908us/step - loss: 0.0013\n",
      "Epoch 806/1000\n",
      "10/10 [==============================] - 0s 902us/step - loss: 0.0012\n",
      "Epoch 807/1000\n",
      "10/10 [==============================] - 0s 898us/step - loss: 0.0012\n",
      "Epoch 808/1000\n",
      "10/10 [==============================] - 0s 771us/step - loss: 0.0012\n",
      "Epoch 809/1000\n",
      "10/10 [==============================] - 0s 918us/step - loss: 0.0012\n",
      "Epoch 810/1000\n",
      "10/10 [==============================] - 0s 897us/step - loss: 0.0012\n",
      "Epoch 811/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 812/1000\n",
      "10/10 [==============================] - 0s 816us/step - loss: 0.0012\n",
      "Epoch 813/1000\n",
      "10/10 [==============================] - 0s 828us/step - loss: 0.0012\n",
      "Epoch 814/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 815/1000\n",
      "10/10 [==============================] - 0s 896us/step - loss: 0.0012\n",
      "Epoch 816/1000\n",
      "10/10 [==============================] - 0s 920us/step - loss: 0.0012\n",
      "Epoch 817/1000\n",
      "10/10 [==============================] - 0s 810us/step - loss: 0.0012\n",
      "Epoch 818/1000\n",
      "10/10 [==============================] - 0s 798us/step - loss: 0.0012\n",
      "Epoch 819/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 820/1000\n",
      "10/10 [==============================] - 0s 865us/step - loss: 0.0012\n",
      "Epoch 821/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 822/1000\n",
      "10/10 [==============================] - 0s 930us/step - loss: 0.0011\n",
      "Epoch 823/1000\n",
      "10/10 [==============================] - 0s 761us/step - loss: 0.0011\n",
      "Epoch 824/1000\n",
      "10/10 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 825/1000\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.0011\n",
      "Epoch 826/1000\n",
      "10/10 [==============================] - 0s 864us/step - loss: 0.0011\n",
      "Epoch 827/1000\n",
      "10/10 [==============================] - 0s 793us/step - loss: 0.0011\n",
      "Epoch 828/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 829/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 830/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 831/1000\n",
      "10/10 [==============================] - 0s 823us/step - loss: 0.0011\n",
      "Epoch 832/1000\n",
      "10/10 [==============================] - 0s 758us/step - loss: 0.0011\n",
      "Epoch 833/1000\n",
      "10/10 [==============================] - 0s 915us/step - loss: 0.0011\n",
      "Epoch 834/1000\n",
      "10/10 [==============================] - 0s 899us/step - loss: 0.0011\n",
      "Epoch 835/1000\n",
      "10/10 [==============================] - 0s 999us/step - loss: 0.0011\n",
      "Epoch 836/1000\n",
      "10/10 [==============================] - 0s 889us/step - loss: 0.0011\n",
      "Epoch 837/1000\n",
      "10/10 [==============================] - 0s 794us/step - loss: 0.0010\n",
      "Epoch 838/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 839/1000\n",
      "10/10 [==============================] - 0s 864us/step - loss: 0.0010\n",
      "Epoch 840/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 841/1000\n",
      "10/10 [==============================] - 0s 853us/step - loss: 0.0010\n",
      "Epoch 842/1000\n",
      "10/10 [==============================] - 0s 763us/step - loss: 0.0010\n",
      "Epoch 843/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 844/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 845/1000\n",
      "10/10 [==============================] - 0s 898us/step - loss: 0.0010\n",
      "Epoch 846/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 9.9505e-04\n",
      "Epoch 847/1000\n",
      "10/10 [==============================] - 0s 830us/step - loss: 9.8962e-04\n",
      "Epoch 848/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 9.8377e-04\n",
      "Epoch 849/1000\n",
      "10/10 [==============================] - 0s 990us/step - loss: 9.7818e-04\n",
      "Epoch 850/1000\n",
      "10/10 [==============================] - 0s 818us/step - loss: 9.7262e-04\n",
      "Epoch 851/1000\n",
      "10/10 [==============================] - 0s 946us/step - loss: 9.6754e-04\n",
      "Epoch 852/1000\n",
      "10/10 [==============================] - 0s 862us/step - loss: 9.6204e-04\n",
      "Epoch 853/1000\n",
      "10/10 [==============================] - 0s 778us/step - loss: 9.5689e-04\n",
      "Epoch 854/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 9.5162e-04\n",
      "Epoch 855/1000\n",
      "10/10 [==============================] - 0s 891us/step - loss: 9.4597e-04\n",
      "Epoch 856/1000\n",
      "10/10 [==============================] - 0s 948us/step - loss: 9.4040e-04\n",
      "Epoch 857/1000\n",
      "10/10 [==============================] - 0s 842us/step - loss: 9.3543e-04\n",
      "Epoch 858/1000\n",
      "10/10 [==============================] - 0s 933us/step - loss: 9.3014e-04\n",
      "Epoch 859/1000\n",
      "10/10 [==============================] - 0s 959us/step - loss: 9.2469e-04\n",
      "Epoch 860/1000\n",
      "10/10 [==============================] - 0s 820us/step - loss: 9.1968e-04\n",
      "Epoch 861/1000\n",
      "10/10 [==============================] - 0s 877us/step - loss: 9.1423e-04\n",
      "Epoch 862/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 9.0943e-04\n",
      "Epoch 863/1000\n",
      "10/10 [==============================] - 0s 916us/step - loss: 9.0423e-04\n",
      "Epoch 864/1000\n",
      "10/10 [==============================] - 0s 999us/step - loss: 8.9924e-04\n",
      "Epoch 865/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 8.9430e-04\n",
      "Epoch 866/1000\n",
      "10/10 [==============================] - 0s 870us/step - loss: 8.8923e-04\n",
      "Epoch 867/1000\n",
      "10/10 [==============================] - 0s 759us/step - loss: 8.8420e-04\n",
      "Epoch 868/1000\n",
      "10/10 [==============================] - 0s 952us/step - loss: 8.7935e-04\n",
      "Epoch 869/1000\n",
      "10/10 [==============================] - 0s 892us/step - loss: 8.7389e-04\n",
      "Epoch 870/1000\n",
      "10/10 [==============================] - 0s 821us/step - loss: 8.6903e-04\n",
      "Epoch 871/1000\n",
      "10/10 [==============================] - 0s 795us/step - loss: 8.6410e-04\n",
      "Epoch 872/1000\n",
      "10/10 [==============================] - 0s 893us/step - loss: 8.5905e-04\n",
      "Epoch 873/1000\n",
      "10/10 [==============================] - 0s 847us/step - loss: 8.5424e-04\n",
      "Epoch 874/1000\n",
      "10/10 [==============================] - 0s 851us/step - loss: 8.4960e-04\n",
      "Epoch 875/1000\n",
      "10/10 [==============================] - 0s 927us/step - loss: 8.4458e-04\n",
      "Epoch 876/1000\n",
      "10/10 [==============================] - 0s 851us/step - loss: 8.3998e-04\n",
      "Epoch 877/1000\n",
      "10/10 [==============================] - 0s 845us/step - loss: 8.3523e-04\n",
      "Epoch 878/1000\n",
      "10/10 [==============================] - 0s 840us/step - loss: 8.3038e-04\n",
      "Epoch 879/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 8.2586e-04\n",
      "Epoch 880/1000\n",
      "10/10 [==============================] - 0s 812us/step - loss: 8.2139e-04\n",
      "Epoch 881/1000\n",
      "10/10 [==============================] - 0s 842us/step - loss: 8.1664e-04\n",
      "Epoch 882/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 8.1223e-04\n",
      "Epoch 883/1000\n",
      "10/10 [==============================] - 0s 919us/step - loss: 8.0735e-04\n",
      "Epoch 884/1000\n",
      "10/10 [==============================] - 0s 910us/step - loss: 8.0292e-04\n",
      "Epoch 885/1000\n",
      "10/10 [==============================] - 0s 861us/step - loss: 7.9819e-04\n",
      "Epoch 886/1000\n",
      "10/10 [==============================] - 0s 873us/step - loss: 7.9390e-04\n",
      "Epoch 887/1000\n",
      "10/10 [==============================] - 0s 762us/step - loss: 7.8920e-04\n",
      "Epoch 888/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.8466e-04\n",
      "Epoch 889/1000\n",
      "10/10 [==============================] - 0s 864us/step - loss: 7.8028e-04\n",
      "Epoch 890/1000\n",
      "10/10 [==============================] - 0s 839us/step - loss: 7.7584e-04\n",
      "Epoch 891/1000\n",
      "10/10 [==============================] - 0s 803us/step - loss: 7.7146e-04\n",
      "Epoch 892/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.6722e-04\n",
      "Epoch 893/1000\n",
      "10/10 [==============================] - 0s 814us/step - loss: 7.6304e-04\n",
      "Epoch 894/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.5878e-04\n",
      "Epoch 895/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.5456e-04\n",
      "Epoch 896/1000\n",
      "10/10 [==============================] - 0s 828us/step - loss: 7.5031e-04\n",
      "Epoch 897/1000\n",
      "10/10 [==============================] - 0s 928us/step - loss: 7.4598e-04\n",
      "Epoch 898/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.4184e-04\n",
      "Epoch 899/1000\n",
      "10/10 [==============================] - 0s 760us/step - loss: 7.3775e-04\n",
      "Epoch 900/1000\n",
      "10/10 [==============================] - 0s 852us/step - loss: 7.3377e-04\n",
      "Epoch 901/1000\n",
      "10/10 [==============================] - 0s 928us/step - loss: 7.2979e-04\n",
      "Epoch 902/1000\n",
      "10/10 [==============================] - 0s 874us/step - loss: 7.2569e-04\n",
      "Epoch 903/1000\n",
      "10/10 [==============================] - 0s 910us/step - loss: 7.2169e-04\n",
      "Epoch 904/1000\n",
      "10/10 [==============================] - 0s 791us/step - loss: 7.1778e-04\n",
      "Epoch 905/1000\n",
      "10/10 [==============================] - 0s 746us/step - loss: 7.1378e-04\n",
      "Epoch 906/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 7.0977e-04\n",
      "Epoch 907/1000\n",
      "10/10 [==============================] - 0s 905us/step - loss: 7.0577e-04\n",
      "Epoch 908/1000\n",
      "10/10 [==============================] - 0s 953us/step - loss: 7.0190e-04\n",
      "Epoch 909/1000\n",
      "10/10 [==============================] - 0s 845us/step - loss: 6.9793e-04\n",
      "Epoch 910/1000\n",
      "10/10 [==============================] - 0s 748us/step - loss: 6.9407e-04\n",
      "Epoch 911/1000\n",
      "10/10 [==============================] - 0s 860us/step - loss: 6.9034e-04\n",
      "Epoch 912/1000\n",
      "10/10 [==============================] - 0s 807us/step - loss: 6.8622e-04\n",
      "Epoch 913/1000\n",
      "10/10 [==============================] - 0s 838us/step - loss: 6.8244e-04\n",
      "Epoch 914/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.7850e-04\n",
      "Epoch 915/1000\n",
      "10/10 [==============================] - 0s 805us/step - loss: 6.7461e-04\n",
      "Epoch 916/1000\n",
      "10/10 [==============================] - 0s 819us/step - loss: 6.7064e-04\n",
      "Epoch 917/1000\n",
      "10/10 [==============================] - 0s 835us/step - loss: 6.6671e-04\n",
      "Epoch 918/1000\n",
      "10/10 [==============================] - 0s 828us/step - loss: 6.6309e-04\n",
      "Epoch 919/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.5928e-04\n",
      "Epoch 920/1000\n",
      "10/10 [==============================] - 0s 810us/step - loss: 6.5562e-04\n",
      "Epoch 921/1000\n",
      "10/10 [==============================] - 0s 761us/step - loss: 6.5201e-04\n",
      "Epoch 922/1000\n",
      "10/10 [==============================] - 0s 739us/step - loss: 6.4846e-04\n",
      "Epoch 923/1000\n",
      "10/10 [==============================] - 0s 986us/step - loss: 6.4475e-04\n",
      "Epoch 924/1000\n",
      "10/10 [==============================] - 0s 887us/step - loss: 6.4125e-04\n",
      "Epoch 925/1000\n",
      "10/10 [==============================] - 0s 877us/step - loss: 6.3780e-04\n",
      "Epoch 926/1000\n",
      "10/10 [==============================] - 0s 834us/step - loss: 6.3438e-04\n",
      "Epoch 927/1000\n",
      "10/10 [==============================] - 0s 804us/step - loss: 6.3064e-04\n",
      "Epoch 928/1000\n",
      "10/10 [==============================] - 0s 985us/step - loss: 6.2728e-04\n",
      "Epoch 929/1000\n",
      "10/10 [==============================] - 0s 751us/step - loss: 6.2371e-04\n",
      "Epoch 930/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.2029e-04\n",
      "Epoch 931/1000\n",
      "10/10 [==============================] - 0s 909us/step - loss: 6.1693e-04\n",
      "Epoch 932/1000\n",
      "10/10 [==============================] - 0s 844us/step - loss: 6.1352e-04\n",
      "Epoch 933/1000\n",
      "10/10 [==============================] - 0s 893us/step - loss: 6.0998e-04\n",
      "Epoch 934/1000\n",
      "10/10 [==============================] - 0s 838us/step - loss: 6.0649e-04\n",
      "Epoch 935/1000\n",
      "10/10 [==============================] - 0s 851us/step - loss: 6.0323e-04\n",
      "Epoch 936/1000\n",
      "10/10 [==============================] - 0s 864us/step - loss: 5.9972e-04\n",
      "Epoch 937/1000\n",
      "10/10 [==============================] - 0s 816us/step - loss: 5.9647e-04\n",
      "Epoch 938/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.9299e-04\n",
      "Epoch 939/1000\n",
      "10/10 [==============================] - 0s 966us/step - loss: 5.8958e-04\n",
      "Epoch 940/1000\n",
      "10/10 [==============================] - 0s 867us/step - loss: 5.8642e-04\n",
      "Epoch 941/1000\n",
      "10/10 [==============================] - 0s 928us/step - loss: 5.8320e-04\n",
      "Epoch 942/1000\n",
      "10/10 [==============================] - 0s 839us/step - loss: 5.7996e-04\n",
      "Epoch 943/1000\n",
      "10/10 [==============================] - 0s 943us/step - loss: 5.7683e-04\n",
      "Epoch 944/1000\n",
      "10/10 [==============================] - 0s 945us/step - loss: 5.7364e-04\n",
      "Epoch 945/1000\n",
      "10/10 [==============================] - 0s 831us/step - loss: 5.7027e-04\n",
      "Epoch 946/1000\n",
      "10/10 [==============================] - 0s 833us/step - loss: 5.6710e-04\n",
      "Epoch 947/1000\n",
      "10/10 [==============================] - 0s 939us/step - loss: 5.6407e-04\n",
      "Epoch 948/1000\n",
      "10/10 [==============================] - 0s 810us/step - loss: 5.6089e-04\n",
      "Epoch 949/1000\n",
      "10/10 [==============================] - 0s 782us/step - loss: 5.5778e-04\n",
      "Epoch 950/1000\n",
      "10/10 [==============================] - 0s 993us/step - loss: 5.5456e-04\n",
      "Epoch 951/1000\n",
      "10/10 [==============================] - 0s 990us/step - loss: 5.5153e-04\n",
      "Epoch 952/1000\n",
      "10/10 [==============================] - 0s 963us/step - loss: 5.4847e-04\n",
      "Epoch 953/1000\n",
      "10/10 [==============================] - 0s 968us/step - loss: 5.4539e-04\n",
      "Epoch 954/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.4243e-04\n",
      "Epoch 955/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.3937e-04\n",
      "Epoch 956/1000\n",
      "10/10 [==============================] - 0s 951us/step - loss: 5.3642e-04\n",
      "Epoch 957/1000\n",
      "10/10 [==============================] - 0s 934us/step - loss: 5.3335e-04\n",
      "Epoch 958/1000\n",
      "10/10 [==============================] - 0s 919us/step - loss: 5.3054e-04\n",
      "Epoch 959/1000\n",
      "10/10 [==============================] - 0s 899us/step - loss: 5.2757e-04\n",
      "Epoch 960/1000\n",
      "10/10 [==============================] - 0s 772us/step - loss: 5.2457e-04\n",
      "Epoch 961/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.2161e-04\n",
      "Epoch 962/1000\n",
      "10/10 [==============================] - 0s 851us/step - loss: 5.1847e-04\n",
      "Epoch 963/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.1570e-04\n",
      "Epoch 964/1000\n",
      "10/10 [==============================] - 0s 815us/step - loss: 5.1277e-04\n",
      "Epoch 965/1000\n",
      "10/10 [==============================] - 0s 800us/step - loss: 5.0993e-04\n",
      "Epoch 966/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 5.0719e-04\n",
      "Epoch 967/1000\n",
      "10/10 [==============================] - 0s 870us/step - loss: 5.0442e-04\n",
      "Epoch 968/1000\n",
      "10/10 [==============================] - 0s 930us/step - loss: 5.0161e-04\n",
      "Epoch 969/1000\n",
      "10/10 [==============================] - 0s 805us/step - loss: 4.9881e-04\n",
      "Epoch 970/1000\n",
      "10/10 [==============================] - 0s 736us/step - loss: 4.9624e-04\n",
      "Epoch 971/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.9342e-04\n",
      "Epoch 972/1000\n",
      "10/10 [==============================] - 0s 887us/step - loss: 4.9078e-04\n",
      "Epoch 973/1000\n",
      "10/10 [==============================] - 0s 969us/step - loss: 4.8802e-04\n",
      "Epoch 974/1000\n",
      "10/10 [==============================] - 0s 820us/step - loss: 4.8523e-04\n",
      "Epoch 975/1000\n",
      "10/10 [==============================] - 0s 775us/step - loss: 4.8259e-04\n",
      "Epoch 976/1000\n",
      "10/10 [==============================] - 0s 926us/step - loss: 4.7991e-04\n",
      "Epoch 977/1000\n",
      "10/10 [==============================] - 0s 869us/step - loss: 4.7723e-04\n",
      "Epoch 978/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.7461e-04\n",
      "Epoch 979/1000\n",
      "10/10 [==============================] - 0s 823us/step - loss: 4.7178e-04\n",
      "Epoch 980/1000\n",
      "10/10 [==============================] - 0s 792us/step - loss: 4.6922e-04\n",
      "Epoch 981/1000\n",
      "10/10 [==============================] - 0s 897us/step - loss: 4.6660e-04\n",
      "Epoch 982/1000\n",
      "10/10 [==============================] - 0s 793us/step - loss: 4.6417e-04\n",
      "Epoch 983/1000\n",
      "10/10 [==============================] - 0s 977us/step - loss: 4.6161e-04\n",
      "Epoch 984/1000\n",
      "10/10 [==============================] - 0s 867us/step - loss: 4.5884e-04\n",
      "Epoch 985/1000\n",
      "10/10 [==============================] - 0s 894us/step - loss: 4.5634e-04\n",
      "Epoch 986/1000\n",
      "10/10 [==============================] - 0s 887us/step - loss: 4.5388e-04\n",
      "Epoch 987/1000\n",
      "10/10 [==============================] - 0s 809us/step - loss: 4.5137e-04\n",
      "Epoch 988/1000\n",
      "10/10 [==============================] - 0s 928us/step - loss: 4.4897e-04\n",
      "Epoch 989/1000\n",
      "10/10 [==============================] - 0s 869us/step - loss: 4.4648e-04\n",
      "Epoch 990/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.4396e-04\n",
      "Epoch 991/1000\n",
      "10/10 [==============================] - 0s 933us/step - loss: 4.4147e-04\n",
      "Epoch 992/1000\n",
      "10/10 [==============================] - 0s 987us/step - loss: 4.3912e-04\n",
      "Epoch 993/1000\n",
      "10/10 [==============================] - 0s 819us/step - loss: 4.3657e-04\n",
      "Epoch 994/1000\n",
      "10/10 [==============================] - 0s 856us/step - loss: 4.3418e-04\n",
      "Epoch 995/1000\n",
      "10/10 [==============================] - 0s 730us/step - loss: 4.3181e-04\n",
      "Epoch 996/1000\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 4.2943e-04\n",
      "Epoch 997/1000\n",
      "10/10 [==============================] - 0s 828us/step - loss: 4.2708e-04\n",
      "Epoch 998/1000\n",
      "10/10 [==============================] - 0s 834us/step - loss: 4.2477e-04\n",
      "Epoch 999/1000\n",
      "10/10 [==============================] - 0s 946us/step - loss: 4.2238e-04\n",
      "Epoch 1000/1000\n",
      "10/10 [==============================] - 0s 789us/step - loss: 4.2000e-04\n"
     ]
    }
   ],
   "source": [
    "ae_model.fit(x=onehot_corpus, y=onehot_corpus, batch_size=32, epochs=1000)\n",
    "ae_model.save(\"ae_model.h5\")"
   ]
  },
  {
   "source": [
    "# **How to use trained model**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## VI. Load trained model & Get output of 1st FC layer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"ae_model.h5\")\n",
    "we_model = keras.models.Model(inputs=reconstructed_model.inputs, outputs=reconstructed_model.get_layer('dense_7').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(mapping, list_words):\n",
    "  output = []\n",
    "  \n",
    "  for word in list_words:\n",
    "    word_vector = [0 for _ in range(vocab_size)]\n",
    "\n",
    "    if word in mapping.keys():\n",
    "      word_index = mapping[word]\n",
    "      word_vector[word_index] = 1\n",
    "    \n",
    "    output.append(word_vector)\n",
    "  \n",
    "  return output"
   ]
  },
  {
   "source": [
    "## VII. Test model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x18c037550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[1.93307301e-10 8.34066358e-11 1.52166649e-07 4.79718835e-07\n",
      "  5.68480159e-11 1.79508852e-10 4.64595810e-13 5.08789246e-13\n",
      "  4.50998243e-08 1.09208786e-09 7.04806746e-09 1.11675326e-05\n",
      "  3.79410420e-10 7.03189153e-06 2.86077517e-09 1.06475284e-09\n",
      "  1.57708213e-09 2.80699353e-10 7.11554649e-10 5.11228322e-08\n",
      "  2.87175145e-10 1.64380261e-08 4.07144496e-09 3.82752640e-13\n",
      "  8.29345055e-08 8.10878795e-11 7.86554877e-10 5.06579119e-11\n",
      "  1.15511810e-11 2.81668466e-10 3.90626637e-12 1.67684084e-06\n",
      "  7.14150581e-13 6.20018836e-09 1.03005625e-10 7.01199168e-11\n",
      "  1.53181944e-14 1.39080275e-11 3.83727745e-13 4.93147678e-13\n",
      "  1.86924911e-12 6.68042921e-12 1.80362825e-09 5.39019551e-10\n",
      "  7.63881958e-10 3.04423316e-13 1.38761125e-09 1.98367503e-11\n",
      "  6.36973425e-08 7.74652131e-12 1.29740108e-09 2.04529046e-10\n",
      "  1.68020209e-12 2.26358918e-10 1.23812210e-11 9.94884175e-11\n",
      "  2.78199312e-08 1.46329583e-14 9.69754197e-08 1.70593747e-10\n",
      "  4.96443562e-08 1.00964390e-10 1.06407026e-06 1.18789336e-11\n",
      "  5.94830780e-08 8.59477836e-11 5.39310298e-11 2.68439123e-07\n",
      "  1.74577579e-07 1.03191544e-12 2.03565143e-09 1.49380616e-13\n",
      "  1.44689783e-12 9.11549891e-10 4.67166910e-06 3.52808711e-13\n",
      "  1.23290367e-09 1.14334377e-13 3.04116815e-10 1.30515296e-08\n",
      "  2.53240540e-08 2.30977260e-09 2.50555878e-11 1.62293720e-10\n",
      "  8.94084792e-07 7.15204340e-09 1.77755213e-10 8.31947965e-12\n",
      "  4.45884254e-08 1.36072169e-11 4.50580001e-06 1.43096257e-09\n",
      "  9.21769105e-10 2.15341606e-10 1.12208923e-10 8.23814474e-08\n",
      "  3.60049907e-10 1.10027965e-09 4.44386205e-06 3.87431537e-12\n",
      "  1.18851262e-10 7.32830330e-08 1.14949505e-09 2.23947166e-10\n",
      "  3.95663760e-14 3.04304176e-14 4.65398303e-10 8.40482670e-08\n",
      "  2.20979333e-12 4.44138104e-09 4.48599448e-12 3.09904613e-09\n",
      "  1.32956202e-09 1.07838460e-10 2.06504893e-08 2.83821699e-11\n",
      "  2.67531952e-08 1.95236622e-11 3.86447263e-11 5.64036838e-11\n",
      "  1.01613856e-11 6.56540422e-08 9.57179214e-12 2.05251349e-09\n",
      "  2.46822909e-11 4.11104456e-10 4.32075735e-13 4.44488935e-09\n",
      "  4.22144437e-11 5.09554887e-08 1.01985209e-09 6.01147798e-10\n",
      "  2.43539772e-10 9.27940604e-08 5.14702560e-12 1.44101370e-10\n",
      "  3.80460648e-07 5.04524270e-11 9.14153085e-13 9.55393560e-08\n",
      "  7.66785835e-09 6.92729643e-08 4.51559623e-11 2.28109654e-12\n",
      "  2.17296261e-08 3.75751957e-10 1.21165888e-09 9.20038490e-11\n",
      "  7.33986427e-10 1.07907294e-06 4.02745615e-10 2.47795473e-08\n",
      "  2.03148349e-11 3.13665205e-10 1.53106996e-07 8.03677333e-11\n",
      "  4.46517199e-13 2.02780711e-06 1.88416163e-06 9.86815429e-09\n",
      "  1.37790899e-08 6.53177601e-09 3.63915426e-11 1.57793036e-13\n",
      "  1.52251031e-10 3.76406771e-14 9.75624204e-08 2.20164837e-12\n",
      "  2.47513704e-10 4.40834791e-09 4.49993598e-09 6.50108021e-08\n",
      "  2.29971684e-11 7.08756276e-10 2.24507828e-14 5.66399727e-08\n",
      "  2.81180821e-08 2.52738334e-11 3.52440814e-13 1.60797937e-12\n",
      "  9.03769282e-11 2.10964032e-13 2.85074907e-06 2.22439317e-10\n",
      "  9.44018863e-10 1.56784363e-10 2.64885390e-13 1.05737807e-09\n",
      "  1.84157009e-10 2.80035717e-10 1.24165359e-10 1.83559806e-10\n",
      "  2.05143347e-09 6.10238415e-10 6.92373311e-11 6.92262636e-10\n",
      "  6.30146491e-10 4.93602104e-10 3.79386464e-14 5.55362689e-09\n",
      "  8.65311045e-10 7.15820528e-11 1.24865063e-09 3.71753019e-12\n",
      "  1.25330224e-11 9.67689061e-07 3.44621839e-07 1.05638567e-10\n",
      "  3.42438125e-06 4.06386405e-13 3.58647469e-07 9.99942064e-01\n",
      "  1.19386662e-12 2.53040554e-07 1.77692739e-11 5.79890184e-06\n",
      "  7.61290408e-09 3.01218774e-14 2.73115836e-11 3.19366894e-11\n",
      "  1.11622057e-11 1.01644101e-11 1.26889341e-11 7.37052108e-09\n",
      "  4.71710884e-08 5.57656460e-13 5.40059403e-12 3.43744624e-08\n",
      "  4.53625798e-13]\n",
      " [2.99242174e-07 8.39101288e-11 4.82701417e-08 5.03717235e-10\n",
      "  2.58999933e-09 9.06452069e-09 7.47263640e-11 2.83363443e-06\n",
      "  1.55364262e-06 5.45050394e-10 4.62099223e-07 1.20124798e-06\n",
      "  8.96794674e-08 6.94788804e-09 1.21786164e-10 2.18313653e-06\n",
      "  4.76450768e-10 5.55837909e-09 2.61799740e-12 4.47512866e-06\n",
      "  1.43568712e-10 7.70558639e-13 9.31193317e-11 3.90410264e-08\n",
      "  5.45774981e-08 1.76266963e-06 2.86055069e-11 1.05512144e-11\n",
      "  1.18377930e-05 2.43096265e-10 4.39075443e-09 7.32324965e-12\n",
      "  9.40353766e-06 2.16640547e-06 5.34397179e-13 5.06351849e-10\n",
      "  2.72333072e-08 5.09422904e-09 1.80791169e-08 8.26728694e-08\n",
      "  3.70902582e-13 1.18103893e-09 4.83981296e-07 1.22356084e-11\n",
      "  8.41344239e-09 4.55905508e-10 4.45011785e-13 8.81396645e-09\n",
      "  2.61150025e-11 6.37958186e-10 2.02442063e-09 3.07931014e-09\n",
      "  4.75381938e-08 3.67206567e-08 3.55531569e-08 9.47310910e-11\n",
      "  1.79674851e-13 5.91071896e-12 1.05759279e-09 5.03989042e-07\n",
      "  1.40968851e-11 1.21643822e-07 4.83134810e-10 1.79806246e-12\n",
      "  5.02819546e-07 9.61471791e-10 2.03531627e-08 1.05023157e-09\n",
      "  3.71875725e-10 1.36754508e-07 9.57809243e-06 6.57464128e-09\n",
      "  2.32486066e-08 2.20541736e-07 1.74331731e-08 1.00124176e-09\n",
      "  7.60867411e-12 4.31014335e-09 1.08925896e-10 3.86142028e-06\n",
      "  2.39454238e-07 5.15418177e-12 3.03139956e-07 3.59570684e-09\n",
      "  1.53690891e-08 1.37860141e-08 1.09911058e-08 8.08475942e-12\n",
      "  2.01053023e-08 9.99550045e-01 9.67419851e-08 6.41322939e-10\n",
      "  3.82252547e-05 6.36233843e-10 2.07586490e-10 8.84456508e-09\n",
      "  1.49414314e-10 4.36643063e-07 6.26079988e-09 2.76934475e-10\n",
      "  1.98074943e-08 1.00708775e-08 2.41299133e-11 7.84190988e-08\n",
      "  1.03904574e-09 4.39610488e-07 8.78732198e-10 7.58989209e-15\n",
      "  4.29658739e-11 3.05509018e-09 1.08714183e-10 9.59371471e-12\n",
      "  6.09511926e-06 8.92918095e-09 3.70989142e-08 8.38457392e-09\n",
      "  3.20236682e-09 3.47407138e-11 8.56346674e-07 2.97444269e-09\n",
      "  2.00977451e-12 8.69376038e-07 4.04964690e-12 2.72213401e-06\n",
      "  6.43809059e-08 9.04727737e-10 4.21387786e-11 1.85379278e-07\n",
      "  5.59220371e-06 5.47016192e-08 9.76871153e-11 4.80201567e-09\n",
      "  1.09126022e-05 2.34591756e-11 3.51929930e-09 5.29953013e-07\n",
      "  1.67630651e-06 6.69208521e-06 6.52431321e-12 1.67438272e-10\n",
      "  3.13982262e-09 6.33151132e-08 1.80421898e-06 1.46572034e-12\n",
      "  2.46906454e-11 5.59814566e-07 2.53095767e-09 1.23349313e-08\n",
      "  1.91495531e-08 1.58864467e-11 1.27994092e-13 1.15529986e-07\n",
      "  4.74096977e-12 7.80823584e-09 4.65613368e-07 6.01601324e-10\n",
      "  9.43053191e-10 1.49244284e-10 1.96926675e-09 1.82678372e-10\n",
      "  1.86545996e-13 5.85939075e-11 6.78205825e-10 1.68898417e-09\n",
      "  3.62540153e-09 1.35490037e-08 1.59860103e-09 2.15765979e-07\n",
      "  2.55474021e-07 1.23388258e-10 2.25115002e-08 1.51539527e-11\n",
      "  1.20117333e-10 5.79701300e-05 1.38791353e-10 6.07375053e-11\n",
      "  7.63183516e-10 4.16468964e-07 1.87966279e-07 8.11367645e-05\n",
      "  2.62810893e-08 6.41337081e-08 9.21103378e-07 1.39100420e-09\n",
      "  2.31686959e-09 1.13693854e-09 5.05822641e-07 3.12523646e-10\n",
      "  1.34969099e-07 1.90420894e-06 1.29690661e-10 2.24647909e-08\n",
      "  1.27075600e-05 1.01459934e-08 1.55628726e-07 2.46028193e-08\n",
      "  3.96307120e-09 6.34012467e-05 6.46383455e-07 7.07332082e-10\n",
      "  8.82456330e-09 6.80526260e-11 1.63781933e-05 3.73991929e-06\n",
      "  8.44343068e-11 5.92345454e-14 6.48577858e-11 1.59609748e-08\n",
      "  1.11985372e-10 2.50958448e-10 1.35168543e-10 2.59822136e-10\n",
      "  6.67389259e-07 4.96700636e-08 1.99407268e-09 1.02042697e-09\n",
      "  8.93288325e-06 1.93467534e-10 2.65423896e-08 1.31357321e-11\n",
      "  4.59027226e-11 4.55314952e-12 3.31182548e-09 1.24066615e-08\n",
      "  3.10715609e-06 6.29859775e-10 9.85370206e-12 8.95602711e-13\n",
      "  6.26420442e-05]\n",
      " [9.45990064e-10 9.06581988e-07 1.94162694e-05 4.22597290e-09\n",
      "  2.53003131e-13 1.65085581e-07 4.01668432e-09 2.33870665e-08\n",
      "  4.72603870e-06 4.50998527e-07 7.21012442e-13 1.18102408e-08\n",
      "  4.96539310e-10 1.07077662e-08 1.65634396e-14 1.68187375e-09\n",
      "  1.63753351e-11 2.42080471e-08 2.57752806e-08 4.45285947e-10\n",
      "  3.05302206e-06 3.19829731e-12 1.24187816e-09 1.60044203e-06\n",
      "  8.60372676e-11 1.90808329e-08 2.68520957e-08 1.61481478e-14\n",
      "  3.73980569e-10 4.18932888e-09 4.46639739e-08 1.16648797e-08\n",
      "  4.69801227e-13 1.55597544e-08 8.14939227e-10 3.88911126e-09\n",
      "  1.08412891e-07 5.99281421e-13 2.25620342e-10 1.70482117e-09\n",
      "  3.18312113e-11 3.96457667e-09 5.87726490e-08 2.25872583e-07\n",
      "  3.72452546e-12 2.12321341e-10 1.51230986e-10 6.59100285e-09\n",
      "  8.10809579e-12 2.33410202e-09 7.32174807e-11 1.11842713e-08\n",
      "  2.66843103e-09 5.79724535e-09 4.92114460e-10 2.83222579e-09\n",
      "  2.55987397e-13 1.46999812e-09 1.26052866e-08 4.12810550e-11\n",
      "  2.11314321e-12 9.62873600e-11 7.75020326e-10 3.80740550e-09\n",
      "  8.56531710e-14 1.62196940e-11 1.46564346e-07 2.06923438e-08\n",
      "  4.85811711e-07 4.66885419e-10 5.49754660e-08 2.15901414e-15\n",
      "  6.09248207e-10 1.93498134e-11 1.15157501e-08 1.01957600e-11\n",
      "  8.68138839e-10 2.53363328e-06 2.96471029e-07 3.74846998e-09\n",
      "  5.27979751e-07 4.53108308e-13 4.78906304e-10 7.49340867e-10\n",
      "  4.87692198e-09 5.00821823e-12 3.31721424e-08 3.30868382e-08\n",
      "  3.99148936e-09 1.89725702e-09 6.68186040e-09 2.29148567e-09\n",
      "  2.59252553e-09 2.52196042e-10 2.64345794e-12 7.25986563e-11\n",
      "  3.91677622e-06 6.44475506e-07 7.09280723e-09 3.98815397e-10\n",
      "  7.78311859e-10 2.46166769e-06 4.23541147e-10 3.16897331e-09\n",
      "  5.99496910e-11 1.24906228e-08 4.00146716e-09 1.42007532e-12\n",
      "  3.19679145e-08 4.46065052e-08 4.83934343e-07 2.08885940e-08\n",
      "  2.50941525e-08 2.28506764e-07 1.75297828e-07 2.98568381e-07\n",
      "  1.22289334e-08 8.58259102e-13 4.19630802e-10 4.91313309e-11\n",
      "  1.59280880e-10 8.50473927e-11 1.09365754e-11 7.01467426e-11\n",
      "  3.36358691e-10 5.30154603e-06 2.56950443e-14 8.95617538e-11\n",
      "  1.05577302e-09 2.20379270e-09 2.33702533e-08 8.18845325e-10\n",
      "  2.21411298e-07 2.14520742e-06 3.19258717e-08 2.62615032e-08\n",
      "  1.54373336e-09 2.82008781e-08 3.24189358e-07 3.65870841e-11\n",
      "  7.90456589e-11 8.48684942e-11 3.17317808e-12 7.83210226e-07\n",
      "  2.72785059e-07 6.07652728e-09 3.03882040e-08 9.28377444e-11\n",
      "  2.98610149e-13 4.29951526e-11 5.05347066e-12 9.76409638e-07\n",
      "  4.05775552e-10 9.99929786e-01 1.31928468e-09 1.71124725e-07\n",
      "  2.19232521e-10 6.90038193e-10 2.81755010e-08 2.60929447e-08\n",
      "  1.84945583e-11 1.64580580e-08 1.16015197e-10 2.37178384e-07\n",
      "  1.90789530e-14 1.85146870e-10 4.03979783e-08 5.10005918e-07\n",
      "  7.83014062e-14 3.80773235e-09 9.08942752e-07 4.88231287e-08\n",
      "  3.93796357e-10 1.16986580e-08 5.10837985e-08 3.60681318e-10\n",
      "  4.58098490e-11 5.13076088e-08 7.53282783e-11 5.33119771e-09\n",
      "  9.98371091e-12 5.47934753e-10 2.28337285e-07 1.36365594e-08\n",
      "  6.10906898e-12 3.71608202e-08 1.15889576e-10 6.10289226e-06\n",
      "  7.12819528e-08 4.43235812e-08 1.10384462e-11 1.50824020e-09\n",
      "  7.87865417e-09 4.99075087e-11 5.97930025e-08 3.10750453e-11\n",
      "  1.48374815e-08 9.91253501e-07 6.68174847e-12 6.08276504e-13\n",
      "  3.56549151e-07 1.13016824e-07 8.42107772e-11 4.18112017e-10\n",
      "  5.87904225e-10 7.53023033e-10 1.59136810e-08 1.70602112e-13\n",
      "  3.58106925e-12 1.21112176e-09 1.23350474e-09 1.32869393e-09\n",
      "  7.39192485e-10 1.11986193e-11 2.07048489e-09 6.05103656e-09\n",
      "  2.49556376e-08 1.80692614e-12 6.47503107e-10 2.50430743e-09\n",
      "  4.18017292e-13 1.32685724e-10 5.34036770e-09 2.56422217e-10\n",
      "  1.17005774e-08 5.50049393e-08 1.14726042e-08 5.75231217e-11\n",
      "  6.20848823e-06]\n",
      " [5.15290788e-09 3.47504100e-12 1.46683050e-07 8.31000957e-09\n",
      "  3.42771688e-12 1.85682913e-09 1.93532863e-12 1.77081128e-10\n",
      "  2.39461599e-07 9.62840900e-08 1.03666205e-08 9.99736130e-01\n",
      "  2.35075213e-08 2.45505507e-05 2.98676417e-10 3.52947126e-07\n",
      "  2.91715576e-08 1.22094601e-08 1.51009527e-09 3.18425118e-05\n",
      "  2.31781030e-08 5.38037768e-13 4.31524365e-11 9.51748369e-09\n",
      "  1.49888834e-07 6.46767639e-11 1.42435397e-07 8.17412327e-13\n",
      "  2.09107537e-10 2.88422314e-10 4.63647837e-07 1.20904611e-08\n",
      "  5.13894309e-12 1.64953362e-05 4.62300684e-11 2.43385451e-11\n",
      "  5.48537452e-14 3.74416276e-10 5.88802451e-10 5.32077715e-10\n",
      "  1.60344570e-13 2.27588278e-11 1.67082544e-05 1.92419084e-12\n",
      "  5.65615124e-11 5.16637044e-09 1.94438670e-08 4.83423399e-08\n",
      "  5.36768141e-08 1.08396229e-07 1.13993690e-06 1.96026466e-08\n",
      "  7.12117709e-15 1.11710037e-07 4.21817886e-10 1.86842158e-07\n",
      "  5.58059355e-07 2.31604916e-10 2.79355139e-09 8.84161910e-10\n",
      "  4.33175182e-06 2.74938816e-06 1.20321738e-05 1.33426811e-11\n",
      "  3.07541959e-05 2.83018955e-11 3.02020214e-10 3.44710260e-09\n",
      "  5.04373543e-10 2.11624381e-11 1.86888940e-08 3.52482377e-10\n",
      "  3.07025390e-12 1.90857226e-12 1.01390219e-06 1.41822300e-11\n",
      "  4.47297221e-09 2.28638397e-09 1.73005716e-07 2.30262365e-10\n",
      "  2.92677555e-06 7.31471239e-09 3.48769618e-07 3.77581647e-11\n",
      "  6.12204667e-06 1.28094327e-10 4.44778285e-12 1.63039807e-11\n",
      "  2.29914132e-08 9.05484114e-08 8.68511052e-07 4.00664874e-07\n",
      "  5.65109914e-09 6.22824672e-08 1.12124580e-11 1.63563764e-05\n",
      "  6.71089087e-11 1.49611435e-06 2.14011786e-09 5.34737143e-10\n",
      "  1.56212369e-11 4.77618667e-10 2.53766030e-09 1.50206569e-10\n",
      "  1.03988809e-08 1.84596852e-11 2.92137798e-07 4.45003617e-10\n",
      "  8.35900735e-08 5.61136169e-08 5.67137205e-11 1.03621573e-11\n",
      "  3.10445358e-09 1.65230066e-10 1.33570310e-09 3.33754264e-13\n",
      "  4.90900165e-09 3.56135854e-09 1.07990942e-07 6.48598397e-11\n",
      "  5.52389081e-12 1.12122605e-08 4.05826067e-11 2.18938226e-07\n",
      "  1.18232840e-07 2.62126008e-07 1.06521989e-13 1.83938781e-07\n",
      "  2.78970305e-08 6.31232524e-07 1.65986273e-06 5.82907278e-09\n",
      "  5.88835611e-08 8.01379088e-07 2.99356234e-10 1.36301681e-09\n",
      "  2.60203961e-07 1.19071586e-10 4.12299968e-12 6.04938011e-09\n",
      "  6.44320934e-08 3.13278115e-08 8.98536996e-08 1.45483170e-12\n",
      "  1.11031987e-07 2.08845883e-08 1.52115069e-06 3.48429646e-10\n",
      "  1.35827865e-08 6.44796643e-08 2.36396236e-08 2.09432358e-07\n",
      "  5.86913059e-14 2.55488288e-08 8.43737524e-10 4.11601114e-10\n",
      "  4.59809144e-12 1.51205904e-06 2.15992593e-08 2.72402258e-06\n",
      "  4.88315055e-10 8.97097266e-07 3.07334419e-14 2.39137377e-10\n",
      "  7.14580548e-11 1.10742171e-08 1.36751794e-07 2.64296801e-07\n",
      "  1.30236413e-06 2.54603094e-07 2.95952213e-06 8.65445979e-11\n",
      "  1.13172714e-10 3.68827983e-07 2.01721390e-10 1.50747012e-10\n",
      "  3.56451846e-09 2.14480560e-12 7.65406072e-10 1.28360309e-08\n",
      "  2.96372150e-12 1.79000686e-11 1.09435507e-06 1.19528343e-09\n",
      "  9.17982357e-11 9.09145037e-10 1.93226302e-09 1.10964413e-06\n",
      "  1.56105823e-10 5.58382407e-09 6.44515663e-10 4.82044092e-12\n",
      "  3.71582445e-07 1.14467456e-10 9.49642587e-10 8.43802632e-12\n",
      "  1.62219942e-06 2.58496470e-06 7.18387128e-09 5.94714500e-10\n",
      "  5.63886549e-10 1.63441224e-14 2.46808107e-09 6.49969181e-08\n",
      "  1.58265978e-09 1.40654322e-10 2.22515406e-09 1.81606650e-12\n",
      "  3.67950476e-10 3.31493855e-09 8.16804668e-09 5.33884013e-05\n",
      "  8.94561439e-11 8.16462009e-09 7.88307197e-11 8.05414220e-06\n",
      "  3.36386137e-07 1.03191896e-13 2.72268948e-12 2.79897550e-09\n",
      "  5.20470125e-11 3.79787486e-11 3.04423939e-13 2.16685586e-10\n",
      "  4.19268827e-06 8.42795842e-08 2.14071057e-12 4.19635393e-09\n",
      "  3.10558468e-09]]\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"Trump is the greatest President of American\"\n",
    "\n",
    "preprocess_sentence = preprocess_text(input_sentence)\n",
    "onehot_sentence = encode_onehot(mapping, preprocess_sentence)\n",
    "\n",
    "embedded_sentence = we_model.predict(onehot_sentence)\n",
    "print(embedded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OUTPUT EMBEDDING\n[5.15289766e-09 3.47504100e-12 1.46682908e-07 8.31000957e-09\n 3.42772338e-12 1.85682558e-09 1.93532495e-12 1.77080781e-10\n 2.39461372e-07 9.62842748e-08 1.03666205e-08 9.99736130e-01\n 2.35075213e-08 2.45505507e-05 2.98675279e-10 3.52947438e-07\n 2.91715576e-08 1.22094601e-08 1.51009527e-09 3.18424791e-05\n 2.31781030e-08 5.38037768e-13 4.31523567e-11 9.51748369e-09\n 1.49888692e-07 6.46766390e-11 1.42435397e-07 8.17413899e-13\n 2.09107134e-10 2.88423396e-10 4.63647837e-07 1.20904611e-08\n 5.13895263e-12 1.64953362e-05 4.62300684e-11 2.43384982e-11\n 5.48536402e-14 3.74416997e-10 5.88802451e-10 5.32076716e-10\n 1.60343649e-13 2.27587844e-11 1.67082380e-05 1.92418716e-12\n 5.65612973e-11 5.16638021e-09 1.94438670e-08 4.83424323e-08\n 5.36768141e-08 1.08396229e-07 1.13993690e-06 1.96026466e-08\n 7.12117709e-15 1.11710037e-07 4.21817081e-10 1.86842328e-07\n 5.58059867e-07 2.31604472e-10 2.79354606e-09 8.84160190e-10\n 4.33175182e-06 2.74938543e-06 1.20321620e-05 1.33426560e-11\n 3.07542250e-05 2.83018418e-11 3.02019632e-10 3.44709594e-09\n 5.04373543e-10 2.11624381e-11 1.86888585e-08 3.52481683e-10\n 3.07024805e-12 1.90856510e-12 1.01390026e-06 1.41822300e-11\n 4.47297221e-09 2.28638397e-09 1.73005887e-07 2.30261921e-10\n 2.92677555e-06 7.31472616e-09 3.48769618e-07 3.77582375e-11\n 6.12204076e-06 1.28094091e-10 4.44778285e-12 1.63039807e-11\n 2.29913706e-08 9.05484114e-08 8.68511052e-07 4.00664874e-07\n 5.65108849e-09 6.22824672e-08 1.12124789e-11 1.63563764e-05\n 6.71087838e-11 1.49611571e-06 2.14011386e-09 5.34736144e-10\n 1.56212369e-11 4.77618667e-10 2.53766030e-09 1.50206278e-10\n 1.03988613e-08 1.84596852e-11 2.92137798e-07 4.45002757e-10\n 8.35900735e-08 5.61135103e-08 5.67134013e-11 1.03621374e-11\n 3.10445358e-09 1.65230690e-10 1.33570310e-09 3.33755538e-13\n 4.90900165e-09 3.56135166e-09 1.07990942e-07 6.48599646e-11\n 5.52388040e-12 1.12122605e-08 4.05824506e-11 2.18938439e-07\n 1.18232727e-07 2.62126235e-07 1.06522193e-13 1.83938781e-07\n 2.78970305e-08 6.31233092e-07 1.65986273e-06 5.82909498e-09\n 5.88835611e-08 8.01377553e-07 2.99356234e-10 1.36301936e-09\n 2.60203961e-07 1.19071586e-10 4.12298407e-12 6.04938011e-09\n 6.44319655e-08 3.13278115e-08 8.98536996e-08 1.45482606e-12\n 1.11031987e-07 2.08845883e-08 1.52114922e-06 3.48429646e-10\n 1.35827598e-08 6.44796643e-08 2.36396236e-08 2.09432557e-07\n 5.86913059e-14 2.55488288e-08 8.43735914e-10 4.11601114e-10\n 4.59810011e-12 1.51205904e-06 2.15993001e-08 2.72402508e-06\n 4.88315055e-10 8.97098971e-07 3.07333843e-14 2.39137848e-10\n 7.14579160e-11 1.10742171e-08 1.36751936e-07 2.64297029e-07\n 1.30236288e-06 2.54603322e-07 2.95951941e-06 8.65445979e-11\n 1.13172929e-10 3.68828324e-07 2.01721778e-10 1.50747012e-10\n 3.56451846e-09 2.14480148e-12 7.65407515e-10 1.28360798e-08\n 2.96372150e-12 1.79000009e-11 1.09435405e-06 1.19528110e-09\n 9.17978887e-11 9.09145037e-10 1.93226679e-09 1.10964299e-06\n 1.56105823e-10 5.58382407e-09 6.44513221e-10 4.82044092e-12\n 3.71582445e-07 1.14467671e-10 9.49640810e-10 8.43802632e-12\n 1.62220101e-06 2.58496220e-06 7.18389881e-09 5.94712224e-10\n 5.63885494e-10 1.63441224e-14 2.46808107e-09 6.49969181e-08\n 1.58265678e-09 1.40654322e-10 2.22515406e-09 1.81606650e-12\n 3.67950476e-10 3.31493855e-09 8.16801560e-09 5.33883504e-05\n 8.94561439e-11 8.16462009e-09 7.88307197e-11 8.05412674e-06\n 3.36386449e-07 1.03192093e-13 2.72268427e-12 2.79897550e-09\n 5.20469119e-11 3.79786758e-11 3.04422774e-13 2.16685184e-10\n 4.19268827e-06 8.42795913e-08 2.14070645e-12 4.19634594e-09\n 3.10557868e-09]\n[1.93306926e-10 8.34067954e-11 1.52166649e-07 4.79719290e-07\n 5.68481234e-11 1.79508505e-10 4.64594888e-13 5.08790221e-13\n 4.50999096e-08 1.09208786e-09 7.04808079e-09 1.11675326e-05\n 3.79410420e-10 7.03189153e-06 2.86077517e-09 1.06475484e-09\n 1.57708813e-09 2.80699353e-10 7.11554649e-10 5.11228322e-08\n 2.87175700e-10 1.64380261e-08 4.07145251e-09 3.82754104e-13\n 8.29345055e-08 8.10877199e-11 7.86554877e-10 5.06578147e-11\n 1.15512027e-11 2.81667939e-10 3.90625900e-12 1.67684243e-06\n 7.14151936e-13 6.20018836e-09 1.03005625e-10 7.01199168e-11\n 1.53181944e-14 1.39080006e-11 3.83728477e-13 4.93147678e-13\n 1.86924911e-12 6.68042921e-12 1.80362481e-09 5.39019551e-10\n 7.63881958e-10 3.04423316e-13 1.38761125e-09 1.98367121e-11\n 6.36972217e-08 7.74650656e-12 1.29740108e-09 2.04529046e-10\n 1.68019895e-12 2.26358918e-10 1.23812210e-11 9.94884175e-11\n 2.78199312e-08 1.46329583e-14 9.69754197e-08 1.70593747e-10\n 4.96443562e-08 1.00964390e-10 1.06407026e-06 1.18789562e-11\n 5.94829643e-08 8.59477836e-11 5.39310298e-11 2.68438868e-07\n 1.74577579e-07 1.03191739e-12 2.03564765e-09 1.49381186e-13\n 1.44690336e-12 9.11548170e-10 4.67167365e-06 3.52808711e-13\n 1.23290367e-09 1.14334377e-13 3.04116815e-10 1.30515296e-08\n 2.53240540e-08 2.30976815e-09 2.50555878e-11 1.62293720e-10\n 8.94085645e-07 7.15204340e-09 1.77754866e-10 8.31944756e-12\n 4.45885107e-08 1.36072169e-11 4.50580001e-06 1.43096257e-09\n 9.21767329e-10 2.15341606e-10 1.12208923e-10 8.23814474e-08\n 3.60049907e-10 1.10027965e-09 4.44386205e-06 3.87431537e-12\n 1.18851262e-10 7.32830330e-08 1.14949505e-09 2.23947166e-10\n 3.95664506e-14 3.04304752e-14 4.65398303e-10 8.40482670e-08\n 2.20978921e-12 4.44138948e-09 4.48599448e-12 3.09904613e-09\n 1.32956202e-09 1.07838460e-10 2.06504893e-08 2.83822254e-11\n 2.67531952e-08 1.95236622e-11 3.86447263e-11 5.64036838e-11\n 1.01613665e-11 6.56540422e-08 9.57181036e-12 2.05251349e-09\n 2.46822909e-11 4.11105233e-10 4.32075735e-13 4.44488091e-09\n 4.22144437e-11 5.09553928e-08 1.01985409e-09 6.01148964e-10\n 2.43539772e-10 9.27938828e-08 5.14702560e-12 1.44101647e-10\n 3.80461017e-07 5.04524270e-11 9.14153085e-13 9.55393560e-08\n 7.66787345e-09 6.92729643e-08 4.51557923e-11 2.28109220e-12\n 2.17296261e-08 3.75751236e-10 1.21165655e-09 9.20040294e-11\n 7.33986427e-10 1.07907397e-06 4.02745615e-10 2.47795473e-08\n 2.03148349e-11 3.13665205e-10 1.53107138e-07 8.03677333e-11\n 4.46517199e-13 2.02780711e-06 1.88416163e-06 9.86815429e-09\n 1.37790899e-08 6.53176357e-09 3.63916119e-11 1.57792724e-13\n 1.52251031e-10 3.76406771e-14 9.75624204e-08 2.20164837e-12\n 2.47513704e-10 4.40835635e-09 4.49993598e-09 6.50108021e-08\n 2.29971684e-11 7.08754888e-10 2.24507387e-14 5.66399727e-08\n 2.81180821e-08 2.52738334e-11 3.52441465e-13 1.60798241e-12\n 9.03767616e-11 2.10963232e-13 2.85074634e-06 2.22438901e-10\n 9.44018863e-10 1.56784363e-10 2.64884902e-13 1.05737807e-09\n 1.84157703e-10 2.80035162e-10 1.24165359e-10 1.83559445e-10\n 2.05142570e-09 6.10238415e-10 6.92373311e-11 6.92263968e-10\n 6.30147656e-10 4.93603047e-10 3.79386464e-14 5.55361623e-09\n 8.65311045e-10 7.15821846e-11 1.24865540e-09 3.71753019e-12\n 1.25330224e-11 9.67689971e-07 3.44622180e-07 1.05638567e-10\n 3.42438125e-06 4.06387164e-13 3.58647469e-07 9.99942064e-01\n 1.19386434e-12 2.53040554e-07 1.77693086e-11 5.79889092e-06\n 7.61290408e-09 3.01218198e-14 2.73116356e-11 3.19366270e-11\n 1.11622057e-11 1.01643711e-11 1.26889584e-11 7.37052108e-09\n 4.71710884e-08 5.57656460e-13 5.40059403e-12 3.43744624e-08\n 4.53625798e-13]\n[2.52126370e-07 6.15635931e-10 8.12553047e-09 9.13932638e-07\n 5.01857139e-05 3.44713602e-12 1.35536684e-08 9.73096950e-11\n 3.28330800e-11 8.05042699e-11 3.22551591e-06 6.94523106e-09\n 2.74381318e-08 1.84331924e-07 9.14157916e-10 3.20991589e-09\n 1.57222524e-09 3.55626500e-10 5.72645284e-13 1.74755278e-05\n 3.09965600e-08 4.19613677e-09 3.49980860e-06 4.14623997e-08\n 8.91208010e-11 1.03857758e-08 3.82539278e-10 2.52344421e-06\n 5.13316252e-08 4.91787333e-10 7.95739538e-07 4.78870606e-06\n 3.35097479e-06 5.51916912e-09 9.78426797e-08 9.28181976e-10\n 2.72566808e-07 6.09274131e-10 1.89236724e-10 9.48440437e-10\n 5.28960176e-13 3.61480836e-08 8.29787936e-08 2.71007078e-10\n 8.64932372e-06 3.37377202e-07 2.21577992e-10 5.14219700e-12\n 1.55486440e-11 2.19129142e-05 1.90148043e-07 1.44868639e-09\n 2.02919659e-09 4.69624295e-09 5.26034754e-08 2.28668242e-07\n 5.33940059e-10 2.20934138e-09 1.26808845e-06 2.00437045e-09\n 2.15420848e-10 7.29589666e-10 2.17825924e-10 1.32178338e-10\n 3.90602384e-10 3.69522894e-07 1.80786974e-05 2.65407296e-09\n 1.58279025e-08 2.56687144e-06 1.98016590e-08 4.47419124e-09\n 1.24911864e-07 5.65761047e-06 1.91605682e-08 4.79804685e-09\n 2.38178227e-10 2.75029843e-09 1.06250937e-08 3.81276959e-06\n 3.72652880e-06 1.44566542e-07 4.16601047e-08 2.26083285e-09\n 1.04332048e-05 1.47689079e-08 4.12997664e-10 8.20441198e-12\n 1.71597705e-08 7.35966088e-09 1.39928637e-13 7.10692573e-12\n 7.94655080e-07 2.77520513e-07 1.94909649e-06 1.56393398e-10\n 5.34846223e-10 6.18001483e-11 6.62064465e-08 4.08163373e-07\n 1.29475319e-09 5.09436541e-05 6.93370295e-09 5.76059165e-08\n 7.40547037e-08 1.80040308e-06 1.53691701e-07 2.31039028e-08\n 9.69892743e-12 8.46833237e-13 7.72038362e-08 9.02832831e-09\n 9.55897361e-10 9.90526843e-08 7.96772648e-10 2.45400322e-09\n 5.13191480e-06 4.04209322e-06 1.42339418e-10 1.09944387e-10\n 2.50512494e-06 1.65877300e-05 1.38021026e-08 1.82747463e-11\n 1.52215651e-09 1.22478161e-06 3.52143781e-09 1.95873948e-08\n 1.23659504e-07 2.07068362e-09 2.24394481e-09 2.33712960e-08\n 1.43634537e-07 3.04428731e-08 2.25178773e-08 3.94517585e-10\n 5.35973115e-08 1.17841870e-09 4.12128331e-09 1.91904457e-12\n 2.00052980e-07 4.72539750e-06 1.11725884e-09 2.60976303e-05\n 1.92461300e-08 9.62646022e-12 1.41168459e-06 9.99627233e-01\n 1.71356014e-08 5.16444652e-06 4.69681787e-08 4.55005733e-07\n 1.11550235e-05 2.64592503e-09 1.19270455e-10 5.79809204e-12\n 6.24864072e-08 1.80724269e-10 5.62678295e-08 1.14061424e-06\n 2.46547609e-11 2.44583853e-10 1.67155250e-08 2.41540659e-11\n 1.00817797e-05 3.05696274e-10 2.46796167e-10 2.95509461e-09\n 2.01105834e-07 5.93854637e-08 7.83998786e-08 4.89549237e-08\n 3.19898448e-11 8.22630426e-08 9.95896476e-10 3.37946545e-07\n 3.07232472e-06 1.23275989e-09 6.48962439e-10 6.32831234e-06\n 8.72909689e-10 3.63724375e-08 1.67929546e-08 5.01224262e-09\n 2.32760172e-07 5.43212098e-09 1.21967616e-06 1.17248526e-07\n 1.15551891e-11 6.91717794e-09 5.89460626e-07 4.93711842e-11\n 8.81204983e-07 2.37981279e-09 1.04457179e-07 1.31881572e-08\n 3.44139613e-11 6.99564993e-08 7.52827646e-06 1.05449517e-10\n 8.80538842e-09 2.80883672e-09 7.08091308e-10 5.00219777e-08\n 8.42352438e-11 2.24652719e-09 5.21212868e-08 6.97557290e-11\n 2.20977525e-09 4.42541663e-12 1.94166688e-07 3.22909322e-09\n 1.51316980e-11 1.53144792e-05 1.12768031e-10 6.74690970e-09\n 9.80165371e-09 1.02239312e-06 9.54462287e-09 1.13104610e-08\n 4.04501215e-08 2.18313544e-05 8.35960723e-09 1.37594425e-08\n 4.73743050e-12 8.02669888e-13 1.93516726e-07 1.39564150e-11\n 3.88033668e-11]\nOUTPUT DISTANCE\n0 vs 1:  1.4139404296875\n1 vs 2:  1.4139090776443481\n2 vs 0:  1.413763403892517\n"
     ]
    }
   ],
   "source": [
    "word_0 = \"American\"\n",
    "word_1 = \"Trump\"\n",
    "word_2 = \"peace\"\n",
    "\n",
    "preprocess_words = preprocess_text(' '.join([word_0, word_1, word_2]))\n",
    "onehot_words = encode_onehot(mapping, preprocess_words)\n",
    "\n",
    "word_0_eb, word_1_eb, word_2_eb = we_model.predict(onehot_words)\n",
    "\n",
    "print(\"OUTPUT EMBEDDING\")\n",
    "print(word_0_eb)\n",
    "print(word_1_eb)\n",
    "print(word_2_eb)\n",
    "\n",
    "dst_0_1 = distance.euclidean(word_0_eb, word_1_eb)\n",
    "dst_1_2 = distance.euclidean(word_1_eb, word_2_eb)\n",
    "dst_2_0 = distance.euclidean(word_2_eb, word_0_eb)\n",
    "\n",
    "print(\"OUTPUT DISTANCE\")\n",
    "print(\"0 vs 1: \", dst_0_1)\n",
    "print(\"1 vs 2: \", dst_1_2)\n",
    "print(\"2 vs 0: \", dst_2_0)"
   ]
  }
 ]
}